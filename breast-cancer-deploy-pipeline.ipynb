{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1662485497032
        }
      },
      "outputs": [],
      "source": [
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/deploy-to-cloud/model-register-and-deploy.ipynb\n",
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/deploy-to-local/register-model-deploy-local-advanced.ipynb\n",
        "\n",
        "from azureml.core import  Workspace\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "from azureml.core.environment import Environment \n",
        "from azureml.core.webservice import AciWebservice,Webservice\n",
        "from azureml.core.model import Model,InferenceConfig\n",
        "\n",
        "# interactive_auth = InteractiveLoginAuthentication(tenant_id=\"9ce70869-60db-44fd-abe8-d2767077fc8f\")\n",
        "ws = Workspace.from_config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1662485497184
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workspace name: cselscdhazureml\n",
            "Azure region: eastus2\n",
            "Subscription id: 320d8d57-c87c-4434-827f-59ee7d86687a\n",
            "Resource group: CSELS-CDH-DEV\n"
          ]
        }
      ],
      "source": [
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1662485497336
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1.2\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from azureml.core import Model\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1662485499829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = Model(workspace=ws,name='breast-cancer',version=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1662485499946
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getenv(\"AZUREML_MODEL_DIR\"))\n",
        "#model_path = Model.get_model_path(os.getenv(\"AZUREML_MODEL_DIR\").split('/')[-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1662485509349
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.makedirs('./aml_outputs/',exist_ok=True)\n",
        "# model.download(target_dir='./aml_outputs/',exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./scoring/score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./scoring/score.py\n",
        "\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment. Join this path with the filename of the model file.\n",
        "    # It holds the path to the directory that contains the deployed model (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # If there are multiple models, this value is the path to the directory containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cancer_model.pkl')\n",
        "    # Deserialize the model file back into a sklearn model.\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "\n",
        "\n",
        "input_sample = np.array([[0.393845668409139, -0.7457496952627328, -0.22189398515428446, -0.7676382304726264, -0.6999246324662508, -0.17745016145311038, \n",
        "-0.81484548808207, -0.770581761525873, -0.7189314051409194, 0.07367558407930598, -0.4665409990624931, -0.06425072325003647, -0.667435753669589, \n",
        "-0.10209930505592255, -0.2928749021935234, -0.18393920631817678, -0.8204798568998558, -0.6065568523529427, -0.395651155530143, 0.3134950272756633,\n",
        " -0.8678658791041564, -0.6897420117050609, -0.5598110994362666, -0.723009965205552, -0.6542518616646612, -0.5936861839456196,\n",
        " -0.9574791012332506, -0.9270503937797329, -0.7552651134179409, -0.2651797994882257, -1.0640128515011344]])\n",
        "output_sample = np.array([0])\n",
        "\n",
        "@input_schema('data', NumpyParameterType(input_sample))\n",
        "@output_schema(NumpyParameterType(output_sample))\n",
        "def run(data):\n",
        "    try:\n",
        "        print(\"input_data....\")\n",
        "        print(type(data))\n",
        "        result = model.predict(data)\n",
        "        # You can return any JSON-serializable object.\n",
        "        return \"here is your result = \" + str(result)\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### use custom envirronment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1662485509593
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit-learn==1.1.2\n"
          ]
        }
      ],
      "source": [
        "print('scikit-learn=={}'.format(sklearn.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1662485509713
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "\n",
        "environment = Environment.from_conda_specification(name='mlopspython_scoring', file_path='./conda_dependencies_scoring.yml')\n",
        "environment.docker.enabled = True\n",
        "#environment = Environment('breast_cancer_scoring_env')\n",
        "#environment.python.conda_dependencies = CondaDependencies.create(\n",
        "#    python_version='3.8',\n",
        "#    conda_packages=[\n",
        "#    'pip==20.2.4'],\n",
        "#    pip_packages=[\n",
        "#    'azureml-defaults',\n",
        "#    'pandas',\n",
        "#    'inference-schema[numpy-support]',\n",
        "#    'joblib',\n",
        "#    'numpy',\n",
        "#    'scikit-learn'\n",
        "#])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Create Inference Configuration\n",
        "\n",
        "* file_path: input parameter to Environment constructor. Manages conda and python package dependencies.\n",
        "* env.docker.base_dockerfile: any extra steps you want to inject into docker file\n",
        "* source_directory: holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\n",
        "* entry_script: contains logic specific to initializing your model and running predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1662485547868
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-09-08 09:16:20-04:00 Creating Container Registry if not exists.\n",
            "2022-09-08 09:16:20-04:00 Registering the environment.\n",
            "2022-09-08 09:16:21-04:00 Building image..\n",
            "2022-09-08 09:26:35-04:00 Generating deployment configuration.\n",
            "2022-09-08 09:26:37-04:00 Submitting deployment to compute..\n",
            "2022-09-08 09:26:40-04:00 Checking the status of deployment breast-cancer-custom-service..\n",
            "2022-09-08 09:28:21-04:00 Checking the status of inference endpoint breast-cancer-custom-service.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "\n",
        "service_name = 'breast-cancer-custom-service'\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='./scoring/score.py', environment=environment)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
        "                                                memory_gb=1 )\n",
        "                                                #vnet_name='csels-cdh-dev-vnet', \n",
        "                                                #subnet_name='cdh-azml-dev-snet')\n",
        "\n",
        "\n",
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1662485548018
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# print(service.get_logs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1662485548033
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is your result = [0.]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "input_sample = np.array([[0.393845668409139, -0.7457496952627328, -0.22189398515428446, -0.7676382304726264, -0.6999246324662508, -0.17745016145311038, \n",
        "-0.81484548808207, -0.770581761525873, -0.7189314051409194, 0.07367558407930598, -0.4665409990624931, -0.06425072325003647, -0.667435753669589, \n",
        "-0.10209930505592255, -0.2928749021935234, -0.18393920631817678, -0.8204798568998558, -0.6065568523529427, -0.395651155530143, 0.3134950272756633,\n",
        " -0.8678658791041564, -0.6897420117050609, -0.5598110994362666, -0.723009965205552, -0.6542518616646612, -0.5936861839456196,\n",
        " -0.9574791012332506, -0.9270503937797329, -0.7552651134179409, -0.2651797994882257, -1.0640128515011344]])\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': input_sample.tolist()\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## AKS deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1662489304081
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-09-08 09:55:27-04:00 Creating Container Registry if not exists.\n",
            "2022-09-08 09:55:27-04:00 Registering the environment.\n",
            "2022-09-08 09:55:28-04:00 Use the existing image.\n",
            "2022-09-08 09:55:29-04:00 Creating resources in AKS.\n",
            "2022-09-08 09:55:30-04:00 Submitting deployment to compute.\n",
            "2022-09-08 09:55:31-04:00 Checking the status of deployment breast-cancer-custom-service-aks..\n",
            "2022-09-08 09:57:20-04:00 Checking the status of inference endpoint breast-cancer-custom-service-aks.\n",
            "Succeeded\n",
            "AKS service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n",
            "/bin/bash: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "/bin/bash: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "/bin/bash: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "/bin/bash: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "2022-09-08T13:57:12,154844395+00:00 - iot-server/run \n",
            "2022-09-08T13:57:12,154864296+00:00 - rsyslog/run \n",
            "2022-09-08T13:57:12,167450310+00:00 - gunicorn/run \n",
            "2022-09-08T13:57:12,169015650+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:12,170436185+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-08T13:57:12,171908122+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
            "bash: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/lib/libtinfo.so.6: no version information available (required by bash)\n",
            "2022-09-08T13:57:12,179630115+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-08T13:57:12,183806019+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:12,185499161+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:12,205089151+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20220729.v6\n",
            "2022-09-08T13:57:12,206621189+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:12,207967123+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:12,212145827+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
            "2022-09-08T13:57:12,213695766+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
            "2022-09-08T13:57:12,215136102+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:12,216986048+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
            "\n",
            "2022-09-08T13:57:12,256860845+00:00 - nginx/run \n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "/bin/bash: /azureml-envs/azureml_07aaf71f4332d71d1897c2e84e139941/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "2022-09-08T13:57:12,465328255+00:00 - iot-server/finish 1 0\n",
            "2022-09-08T13:57:12,466779091+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "adal==1.2.7\n",
            "argcomplete==2.0.0\n",
            "attrs==22.1.0\n",
            "azure-common==1.1.28\n",
            "azure-core==1.25.1\n",
            "azure-graphrbac==0.61.1\n",
            "azure-identity==1.10.0\n",
            "azure-mgmt-authorization==2.0.0\n",
            "azure-mgmt-containerregistry==10.0.0\n",
            "azure-mgmt-core==1.3.2\n",
            "azure-mgmt-keyvault==10.1.0\n",
            "azure-mgmt-resource==21.1.0\n",
            "azure-mgmt-storage==20.0.0\n",
            "azureml-core==1.45.0\n",
            "azureml-dataprep==4.2.2\n",
            "azureml-dataprep-native==38.0.0\n",
            "azureml-dataprep-rslex==2.8.1\n",
            "azureml-dataset-runtime==1.45.0\n",
            "azureml-defaults==1.45.0\n",
            "azureml-inference-server-http==0.7.5\n",
            "backports.tempfile==1.0\n",
            "backports.weakref==1.0.post1\n",
            "bcrypt==4.0.0\n",
            "cachetools==5.2.0\n",
            "certifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\n",
            "cffi==1.15.1\n",
            "charset-normalizer==2.1.1\n",
            "click==8.1.3\n",
            "cloudpickle==2.2.0\n",
            "configparser==3.7.4\n",
            "contextlib2==21.6.0\n",
            "cryptography==37.0.4\n",
            "distro==1.7.0\n",
            "docker==5.0.3\n",
            "dotnetcore2==3.1.23\n",
            "Flask==2.1.3\n",
            "Flask-Cors==3.0.10\n",
            "fusepy==3.0.1\n",
            "google-api-core==2.10.0\n",
            "google-auth==2.11.0\n",
            "googleapis-common-protos==1.56.4\n",
            "gunicorn==20.1.0\n",
            "humanfriendly==10.0\n",
            "idna==3.3\n",
            "importlib-metadata==4.12.0\n",
            "importlib-resources==5.9.0\n",
            "inference-schema==1.4.2.1\n",
            "isodate==0.6.1\n",
            "itsdangerous==2.1.2\n",
            "jeepney==0.8.0\n",
            "Jinja2==3.1.2\n",
            "jmespath==1.0.1\n",
            "joblib==1.1.0\n",
            "json-logging-py==0.2\n",
            "jsonpickle==2.2.0\n",
            "jsonschema==4.15.0\n",
            "knack==0.9.0\n",
            "MarkupSafe==2.1.1\n",
            "msal==1.18.0\n",
            "msal-extensions==1.0.0\n",
            "msrest==0.7.1\n",
            "msrestazure==0.6.4\n",
            "ndg-httpsclient==0.5.1\n",
            "numpy==1.23.2\n",
            "oauthlib==3.2.0\n",
            "opencensus==0.11.0\n",
            "opencensus-context==0.1.3\n",
            "opencensus-ext-azure==1.1.7\n",
            "packaging==21.3\n",
            "pandas==1.4.4\n",
            "paramiko==2.11.0\n",
            "pathspec==0.10.1\n",
            "pkginfo==1.8.3\n",
            "pkgutil-resolve-name==1.3.10\n",
            "portalocker==2.5.1\n",
            "protobuf==4.21.5\n",
            "psutil==5.9.2\n",
            "pyarrow==6.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycparser==2.21\n",
            "Pygments==2.13.0\n",
            "PyJWT==2.4.0\n",
            "PyNaCl==1.5.0\n",
            "pyOpenSSL==22.0.0\n",
            "pyparsing==3.0.9\n",
            "pyrsistent==0.18.1\n",
            "PySocks==1.7.1\n",
            "python-dateutil==2.8.2\n",
            "pytz==2022.2.1\n",
            "PyYAML==6.0\n",
            "requests==2.28.1\n",
            "requests-oauthlib==1.3.1\n",
            "rsa==4.9\n",
            "scikit-learn==1.1.2\n",
            "scipy==1.9.1\n",
            "SecretStorage==3.3.3\n",
            "six==1.16.0\n",
            "tabulate==0.8.10\n",
            "threadpoolctl==3.1.0\n",
            "typing-extensions==4.3.0\n",
            "urllib3==1.26.12\n",
            "websocket-client==1.4.1\n",
            "Werkzeug==2.2.2\n",
            "wrapt==1.12.1\n",
            "zipp==3.8.1\n",
            "\n",
            "2022-09-08T13:57:13,318390476+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:13,321990366+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-08T13:57:13,324261522+00:00 | gunicorn/run | AzureML Inference Server\n",
            "2022-09-08T13:57:13,326197471+00:00 | gunicorn/run | ###############################################\n",
            "2022-09-08T13:57:13,327745309+00:00 | gunicorn/run | \n",
            "2022-09-08T13:57:15,250611867+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
            "\n",
            "Azure ML Inferencing HTTP server v0.7.5\n",
            "\n",
            "\n",
            "Server Settings\n",
            "---------------\n",
            "Entry Script Name: main.py\n",
            "Model Directory: /var/azureml-app/azureml-models/breast-cancer/8\n",
            "Worker Count: 1\n",
            "Worker Timeout (seconds): 300\n",
            "Server Port: 31311\n",
            "Application Insights Enabled: false\n",
            "Application Insights Key: AppInsights key provided\n",
            "Inferencing HTTP server version: azmlinfsrv/0.7.5\n",
            "CORS for the specified origins: None\n",
            "\n",
            "\n",
            "Server Routes\n",
            "---------------\n",
            "Liveness Probe: GET   127.0.0.1:31311/\n",
            "Score:          POST  127.0.0.1:31311/score\n",
            "\n",
            "Starting gunicorn 20.1.0\n",
            "Listening at: http://0.0.0.0:31311 (12)\n",
            "Using worker: sync\n",
            "Booting worker with pid: 67\n",
            "Initializing logger\n",
            "2022-09-08 13:57:16,816 | root | INFO | Starting up app insights client\n",
            "logging socket was found. logging is available.\n",
            "logging socket was found. logging is available.\n",
            "2022-09-08 13:57:16,822 | root | INFO | Starting up app insight hooks\n",
            "2022-09-08 13:57:17,058 | root | INFO | Found driver script at /var/azureml-app/main.py and the score script at /structure/azureml-app/score.py\n",
            "2022-09-08 13:57:17,058 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: data.\n",
            "2022-09-08 13:57:17,058 | root | INFO | Invoking user's init function\n",
            "2022-09-08 13:57:18,155 | root | INFO | Users's init has completed successfully\n",
            "2022-09-08 13:57:18,155 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n",
            "2022-09-08 13:57:18,155 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
            "2022-09-08 13:57:18,156 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
            "2022-09-08 13:57:20,578 | root | INFO | 200\n",
            "127.0.0.1 - - [08/Sep/2022:13:57:20 +0000] \"GET /swagger.json HTTP/1.0\" 200 3319 \"-\" \"hackney/1.18.1\"\n",
            "2022-09-08 13:57:26,665 | root | INFO | 200\n",
            "127.0.0.1 - - [08/Sep/2022:13:57:26 +0000] \"GET /swagger.json HTTP/1.0\" 200 3319 \"-\" \"hackney/1.18.1\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-secure-workspace-vnet?tabs=pe%2Ccli\n",
        "\n",
        "from azureml.core.webservice import AksWebservice, Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.compute import AksCompute\n",
        "\n",
        "service_name = 'breast-cancer-custom-service-aks'\n",
        "\n",
        "# TODO Check if compute exits\n",
        "aks_target = AksCompute(ws,\"aks-cdh-dev\")\n",
        "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
        "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
        "# things such as dependencies and AML components.\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, \n",
        "                                                    memory_gb = 1)\n",
        "aks_service = Model.deploy(ws, \n",
        "                        service_name, \n",
        "                        [model], \n",
        "                        inference_config, \n",
        "                        deployment_config, \n",
        "                        aks_target)\n",
        "aks_service.wait_for_deployment(show_output = True)\n",
        "print(aks_service.state)\n",
        "print(aks_service.get_logs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is your result = [0.]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "input_sample = np.array([[0.393845668409139, -0.7457496952627328, -0.22189398515428446, -0.7676382304726264, -0.6999246324662508, -0.17745016145311038, \n",
        "-0.81484548808207, -0.770581761525873, -0.7189314051409194, 0.07367558407930598, -0.4665409990624931, -0.06425072325003647, -0.667435753669589, \n",
        "-0.10209930505592255, -0.2928749021935234, -0.18393920631817678, -0.8204798568998558, -0.6065568523529427, -0.395651155530143, 0.3134950272756633,\n",
        " -0.8678658791041564, -0.6897420117050609, -0.5598110994362666, -0.723009965205552, -0.6542518616646612, -0.5936861839456196,\n",
        " -0.9574791012332506, -0.9270503937797329, -0.7552651134179409, -0.2651797994882257, -1.0640128515011344]])\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': input_sample.tolist()\n",
        "})\n",
        "\n",
        "output = aks_service.run(input_payload)\n",
        "\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('mlopspython')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "a7ce0cb662f1d0fbfd5d85dd76d39702ed5c42e050c073c86250f1b353513f1a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
