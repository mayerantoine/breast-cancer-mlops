{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/deploy-to-cloud/model-register-and-deploy.ipynb\r\n",
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/deploy-to-local/register-model-deploy-local-advanced.ipynb\r\n",
        "\r\n",
        "from azureml.core import  Workspace\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "from azureml.core.environment import Environment \r\n",
        "from azureml.core.webservice import AciWebservice,Webservice\r\n",
        "from azureml.core.model import Model,InferenceConfig\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"9ce70869-60db-44fd-abe8-d2767077fc8f\")\r\n",
        "ws = Workspace.from_config()\r\n"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1661874892803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Workspace name: ' + ws.name, \r\n",
        "      'Azure region: ' + ws.location, \r\n",
        "      'Subscription id: ' + ws.subscription_id, \r\n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: cselscdhazureml\nAzure region: eastus2\nSubscription id: 320d8d57-c87c-4434-827f-59ee7d86687a\nResource group: csels-cdh-dev\n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661874893020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\r\n",
        "from azureml.core import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "\r\n",
        "print(sklearn.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1.1.2\n"
        }
      ],
      "execution_count": 74,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661874893357
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(workspace=ws,name='breast-cancer',version=4)"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661874893798
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.makedirs('./aml_outputs/',exist_ok=True)\r\n",
        "model.download(target_dir='./aml_outputs/',exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 76,
          "data": {
            "text/plain": "'aml_outputs/cancer_model.pkl'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 76,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661874895179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./scoring/score.py\r\n",
        "\r\n",
        "import joblib\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment. Join this path with the filename of the model file.\r\n",
        "    # It holds the path to the directory that contains the deployed model (./azureml-models/$MODEL_NAME/$VERSION)\r\n",
        "    # If there are multiple models, this value is the path to the directory containing all deployed models (./azureml-models)\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cancer_model.pkl')\r\n",
        "    # Deserialize the model file back into a sklearn model.\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "input_sample = np.array([[0.393845668409139, -0.7457496952627328, -0.22189398515428446, -0.7676382304726264, -0.6999246324662508, -0.17745016145311038, \r\n",
        "-0.81484548808207, -0.770581761525873, -0.7189314051409194, 0.07367558407930598, -0.4665409990624931, -0.06425072325003647, -0.667435753669589, \r\n",
        "-0.10209930505592255, -0.2928749021935234, -0.18393920631817678, -0.8204798568998558, -0.6065568523529427, -0.395651155530143, 0.3134950272756633,\r\n",
        " -0.8678658791041564, -0.6897420117050609, -0.5598110994362666, -0.723009965205552, -0.6542518616646612, -0.5936861839456196,\r\n",
        " -0.9574791012332506, -0.9270503937797329, -0.7552651134179409, -0.2651797994882257, -1.0640128515011344]])\r\n",
        "output_sample = np.array([0])\r\n",
        "\r\n",
        "@input_schema('data', NumpyParameterType(input_sample))\r\n",
        "@output_schema(NumpyParameterType(output_sample))\r\n",
        "def run(data):\r\n",
        "    try:\r\n",
        "        print(\"input_data....\")\r\n",
        "        print(type(data))\r\n",
        "        result = model.predict(data)\r\n",
        "        # You can return any JSON-serializable object.\r\n",
        "        return \"here is your result = \" + str(result)\r\n",
        "    except Exception as e:\r\n",
        "        error = str(e)\r\n",
        "        return error"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./scoring/score.py\n"
        }
      ],
      "execution_count": 83,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### use custom envirronment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('scikit-learn=={}'.format(sklearn.__version__))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "scikit-learn==1.1.2\n"
        }
      ],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661875316638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "\r\n",
        "environment = Environment('my-sklearn-environment')\r\n",
        "environment.python.conda_dependencies = CondaDependencies.create(conda_packages=[\r\n",
        "    'pip==20.2.4'],\r\n",
        "    pip_packages=[\r\n",
        "    'azureml-defaults',\r\n",
        "    'pandas',\r\n",
        "    'inference-schema[numpy-support]',\r\n",
        "    'joblib',\r\n",
        "    'numpy',\r\n",
        "    'scikit-learn'\r\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661875321530
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Inference Configuration\r\n",
        "\r\n",
        "* file_path: input parameter to Environment constructor. Manages conda and python package dependencies.\r\n",
        "* env.docker.base_dockerfile: any extra steps you want to inject into docker file\r\n",
        "* source_directory: holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\r\n",
        "* entry_script: contains logic specific to initializing your model and running predictions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "\r\n",
        "service_name = 'breast-cancer-custom-service'\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='./scripts/score.py', environment=environment)\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws,\r\n",
        "                       name=service_name,\r\n",
        "                       models=[model],\r\n",
        "                       inference_config=inference_config,\r\n",
        "                       deployment_config=aci_config,\r\n",
        "                       overwrite=True)\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2022-08-30 16:02:04+00:00 Creating Container Registry if not exists.\n2022-08-30 16:02:04+00:00 Registering the environment.\n2022-08-30 16:02:05+00:00 Generating deployment configuration.\n2022-08-30 16:02:06+00:00 Submitting deployment to compute.\n2022-08-30 16:02:08+00:00 Checking the status of deployment breast-cancer-custom-service..\n2022-08-30 16:07:21+00:00 Checking the status of inference endpoint breast-cancer-custom-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 87,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661875642806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_433da808b29871274053a199d741f839/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_433da808b29871274053a199d741f839/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_433da808b29871274053a199d741f839/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_433da808b29871274053a199d741f839/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2022-08-30T16:06:35,566014488+00:00 - iot-server/run \n2022-08-30T16:06:35,565736285+00:00 - rsyslog/run \n2022-08-30T16:06:35,573609370+00:00 - gunicorn/run \nbash: /azureml-envs/azureml_433da808b29871274053a199d741f839/lib/libtinfo.so.6: no version information available (required by bash)\n2022-08-30T16:06:35,584764692+00:00 | gunicorn/run | \n2022-08-30T16:06:35,596345418+00:00 | gunicorn/run | ###############################################\n2022-08-30T16:06:35,600698065+00:00 - nginx/run \n2022-08-30T16:06:35,619305168+00:00 | gunicorn/run | AzureML Container Runtime Information\n2022-08-30T16:06:35,622332400+00:00 | gunicorn/run | ###############################################\n2022-08-30T16:06:35,634693835+00:00 | gunicorn/run | \n2022-08-30T16:06:35,647275672+00:00 | gunicorn/run | \n2022-08-30T16:06:35,683575467+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20220616.v11\n2022-08-30T16:06:35,690505342+00:00 | gunicorn/run | \n2022-08-30T16:06:35,698452029+00:00 | gunicorn/run | \n2022-08-30T16:06:35,708115934+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_433da808b29871274053a199d741f839/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2022-08-30T16:06:35,711036766+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2022-08-30T16:06:35,716152721+00:00 | gunicorn/run | \n2022-08-30T16:06:35,721169476+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n/bin/bash: /azureml-envs/azureml_433da808b29871274053a199d741f839/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2022-08-30T16:06:36,028713722+00:00 - iot-server/finish 1 0\n2022-08-30T16:06:36,039765042+00:00 - Exit code 1 is normal. Not restarting iot-server.\nadal==1.2.7\napplicationinsights==0.11.10\nargcomplete==2.0.0\nattrs==22.1.0\nazure-common==1.1.28\nazure-core==1.25.0\nazure-graphrbac==0.61.1\nazure-identity==1.7.0\nazure-mgmt-authorization==2.0.0\nazure-mgmt-containerregistry==10.0.0\nazure-mgmt-core==1.3.0\nazure-mgmt-keyvault==10.1.0\nazure-mgmt-resource==21.1.0\nazure-mgmt-storage==20.0.0\nazureml-core==1.43.0\nazureml-dataprep==4.0.4\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.6.3\nazureml-dataset-runtime==1.43.0.post2\nazureml-defaults==1.43.0\nazureml-inference-server-http==0.4.14\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.0\ncachetools==5.2.0\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\ncffi==1.15.1\ncharset-normalizer==2.1.1\nclick==7.1.2\ncloudpickle==2.1.0\nconfigparser==3.7.4\ncontextlib2==21.6.0\ncryptography==37.0.4\ndistro==1.7.0\ndocker==5.0.3\ndotnetcore2==3.1.23\nFlask==1.0.3\nfusepy==3.0.1\ngoogle-api-core==2.8.2\ngoogle-auth==2.11.0\ngoogleapis-common-protos==1.56.4\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna==3.3\nimportlib-resources==5.9.0\ninference-schema==1.4.2.1\nisodate==0.6.1\nitsdangerous==1.1.0\njeepney==0.8.0\nJinja2==3.0.3\njmespath==1.0.0\njoblib==1.1.0\njson-logging-py==0.2\njsonpickle==2.2.0\njsonschema==4.14.0\nknack==0.9.0\nMarkupSafe==2.1.1\nmsal==1.18.0\nmsal-extensions==1.0.0\nmsrest==0.6.21\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy==1.23.2\noauthlib==3.2.0\nopencensus==0.11.0\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.7\npackaging==21.3\npandas==1.4.3\nparamiko==2.11.0\npathspec==0.9.0\npkginfo==1.8.3\npkgutil-resolve-name==1.3.10\nportalocker==2.5.1\nprotobuf==4.21.5\npsutil==5.9.1\npyarrow==3.0.0\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.21\nPygments==2.13.0\nPyJWT==2.4.0\nPyNaCl==1.5.0\npyOpenSSL==22.0.0\npyparsing==3.0.9\npyrsistent==0.18.1\nPySocks==1.7.1\npython-dateutil==2.8.2\npytz==2022.2.1\nPyYAML==6.0\nrequests==2.28.1\nrequests-oauthlib==1.3.1\nrsa==4.9\nscikit-learn==1.1.2\nscipy==1.9.1\nSecretStorage==3.3.3\nsix==1.16.0\ntabulate==0.8.10\nthreadpoolctl==3.1.0\ntyping-extensions==4.3.0\nurllib3==1.26.9\nwebsocket-client==1.4.0\nWerkzeug==1.0.1\nwrapt==1.12.1\nzipp==3.8.1\n\n2022-08-30T16:06:37,009291415+00:00 | gunicorn/run | \n2022-08-30T16:06:37,014370176+00:00 | gunicorn/run | ###############################################\n2022-08-30T16:06:37,016325899+00:00 | gunicorn/run | AzureML Inference Server\n2022-08-30T16:06:37,026633921+00:00 | gunicorn/run | ###############################################\n2022-08-30T16:06:37,029544956+00:00 | gunicorn/run | \n2022-08-30T16:06:37,033263700+00:00 | gunicorn/run | \n2022-08-30T16:06:37,035371425+00:00 | gunicorn/run | Starting HTTP server\n2022-08-30T16:06:37,037585951+00:00 | gunicorn/run | \nStarting gunicorn 20.1.0\nListening at: http://127.0.0.1:31311 (73)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 124\nSPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2022-08-30 16:06:38,882 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2022-08-30 16:06:38,884 | root | INFO | Starting up request id generator\n2022-08-30 16:06:38,884 | root | INFO | Starting up app insight hooks\n2022-08-30 16:06:38,887 | root | INFO | Invoking user's init function\n2022-08-30 16:06:40,256 | root | INFO | Users's init has completed successfully\n2022-08-30 16:06:40,264 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n2022-08-30 16:06:40,264 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\nGenerating swagger file: /tmp/tmp57zn4i86\n2022-08-30 16:06:40,267 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n2022-08-30 16:07:21,706 | root | INFO | 200\n127.0.0.1 - - [30/Aug/2022:16:07:21 +0000] \"GET /swagger.json HTTP/1.0\" 200 2725 \"-\" \"Go-http-client/1.1\"\n2022-08-30 16:07:22,547 | root | INFO | 200\n127.0.0.1 - - [30/Aug/2022:16:07:22 +0000] \"GET /swagger.json HTTP/1.0\" 200 2725 \"-\" \"Go-http-client/1.1\"\n\n"
        }
      ],
      "execution_count": 88,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661875647852
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "\r\n",
        "input_sample = np.array([[0.393845668409139, -0.7457496952627328, -0.22189398515428446, -0.7676382304726264, -0.6999246324662508, -0.17745016145311038, \r\n",
        "-0.81484548808207, -0.770581761525873, -0.7189314051409194, 0.07367558407930598, -0.4665409990624931, -0.06425072325003647, -0.667435753669589, \r\n",
        "-0.10209930505592255, -0.2928749021935234, -0.18393920631817678, -0.8204798568998558, -0.6065568523529427, -0.395651155530143, 0.3134950272756633,\r\n",
        " -0.8678658791041564, -0.6897420117050609, -0.5598110994362666, -0.723009965205552, -0.6542518616646612, -0.5936861839456196,\r\n",
        " -0.9574791012332506, -0.9270503937797329, -0.7552651134179409, -0.2651797994882257, -1.0640128515011344]])\r\n",
        "\r\n",
        "input_payload = json.dumps({\r\n",
        "    'data': input_sample.tolist()\r\n",
        "})\r\n",
        "\r\n",
        "output = service.run(input_payload)\r\n",
        "\r\n",
        "print(output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "here is your result = [0.]\n"
        }
      ],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661875987305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "# The example below assumes JSON formatting which may be updated\r\n",
        "# depending on the format your endpoint expects.\r\n",
        "# More information can be found here:\r\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\r\n",
        "data =  {\r\n",
        "  \"data\": [\r\n",
        "    [\r\n",
        "      0.393845668409139,\r\n",
        "      -0.7457496952627328,\r\n",
        "      -0.22189398515428446,\r\n",
        "      -0.7676382304726264,\r\n",
        "      -0.6999246324662508,\r\n",
        "      -0.17745016145311038,\r\n",
        "      -0.81484548808207,\r\n",
        "      -0.770581761525873,\r\n",
        "      -0.7189314051409194,\r\n",
        "      0.07367558407930598,\r\n",
        "      -0.4665409990624931,\r\n",
        "      -0.06425072325003647,\r\n",
        "      -0.667435753669589,\r\n",
        "      -0.10209930505592255,\r\n",
        "      -0.2928749021935234,\r\n",
        "      -0.18393920631817678,\r\n",
        "      -0.8204798568998558,\r\n",
        "      -0.6065568523529427,\r\n",
        "      -0.395651155530143,\r\n",
        "      0.3134950272756633,\r\n",
        "      -0.8678658791041564,\r\n",
        "      -0.6897420117050609,\r\n",
        "      -0.5598110994362666,\r\n",
        "      -0.723009965205552,\r\n",
        "      -0.6542518616646612,\r\n",
        "      -0.5936861839456196,\r\n",
        "      -0.9574791012332506,\r\n",
        "      -0.9270503937797329,\r\n",
        "      -0.7552651134179409,\r\n",
        "      -0.2651797994882257,\r\n",
        "      -1.0640128515011344\r\n",
        "    ]\r\n",
        "  ]\r\n",
        "}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'http://d29e1866-d35b-4f23-8827-ea1dd1bffd9a.eastus2.azurecontainer.io/score'\r\n",
        "api_key = '' # Replace this with the API key for the web service\r\n",
        "\r\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\r\n",
        "# Remove this header to have the request observe the endpoint traffic rules\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "b'\"here is your result = [0.]\"'\n"
        }
      ],
      "execution_count": 94,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661875915462
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}